{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import time\n",
    "from imutils.video import FPS, WebcamVideoStream\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, LearningRateScheduler\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K \n",
    "from keras.models import load_model\n",
    "from math import ceil \n",
    "import numpy as np \n",
    "from termcolor import colored\n",
    "\n",
    "from mn_model import mn_model\n",
    "from face_generator import BatchGenerator\n",
    "from keras_ssd_loss import SSDLoss\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "\n",
    "# training parameters\n",
    "from keras import backend as K\n",
    "import scipy.misc as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "img_height =512\n",
    "img_width = 512\n",
    "\n",
    "img_channels = 3\n",
    "\n",
    "n_classes =2 \n",
    "class_names = [\"background\",\"face\"]\n",
    "\n",
    "scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # anchorboxes for coco dataset\n",
    "aspect_ratios = [[0.5, 1.0, 2.0],\n",
    "                 [1.0/3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "                 [1.0/3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "                 [1.0/3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "                 [0.5, 1.0, 2.0],\n",
    "                 [0.5, 1.0, 2.0]] # The anchor box aspect ratios used in the original SSD300\n",
    "two_boxes_for_ar1 = True\n",
    "limit_boxes = True # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = 'centroids' # Whether the box coordinates to be used as targets for the model should be in the 'centroids' or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "det_model_path = \"./models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_demo(model):\n",
    "    def predict(frame):\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        _CONF = 0.60 \n",
    "        _IOU = 0.15\n",
    "\n",
    "        frame_scaled = np.zeros((img_height, img_width, img_channels))\n",
    "\n",
    "        for idx in range(img_channels):\n",
    "            frame_scaled[:, :, idx] = cv2.resize(frame[:, :, idx], (img_height, img_width), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "        img = np.expand_dims(frame_scaled, axis=0)\n",
    "\n",
    "        y_pred = model.predict(img)\n",
    "\n",
    "\n",
    "        result = decode_y2(y_pred,\n",
    "                                confidence_thresh=_CONF,\n",
    "                                iou_threshold=_IOU,\n",
    "                                top_k='all',\n",
    "                                input_coords=coords,\n",
    "                                normalize_coords=normalize_coords,\n",
    "                                img_height=img_height,\n",
    "                                img_width=img_width)[0]\n",
    "\n",
    "\n",
    "        np.set_printoptions(suppress=True)        \n",
    "                \n",
    "        # scale each detection back up to the image\n",
    "        scale = np.array([width/img_width, width/img_width, height/img_height, height/img_height])\n",
    "\n",
    "        for i in range(len(result)):\n",
    "            if result[i][1] < 0.6:\n",
    "                print('conf < 0.6')\n",
    "            pt = result[i][2:]\n",
    "            pt *= scale\n",
    "            pt = pt.astype(int)\n",
    "            cv2.rectangle(frame, (pt[0], pt[2]), (pt[1], pt[3]), COLORS[i % 3], 2)\n",
    "#             cv2.putText(frame, 'person', (pt[0], pt[2]), FONT, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "    # start video stream thread, allow buffer to fill\n",
    "    print(\"[INFO] starting threaded video stream...\")\n",
    "    stream = WebcamVideoStream(src=0).start()  # default camera\n",
    "    time.sleep(1.0)\n",
    "    # start fps timer\n",
    "    # loop over frames from the video file stream\n",
    "    while True:\n",
    "        # grab next frame\n",
    "        frame = stream.read()\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # update FPS counter\n",
    "        fps.update()\n",
    "        frame = predict(frame)\n",
    "\n",
    "        # keybindings for display\n",
    "        if key == ord('p'):  # pause\n",
    "            while True:\n",
    "                key2 = cv2.waitKey(1) or 0xff\n",
    "                cv2.imshow('frame', frame)\n",
    "                if key2 == ord('p'):  # resume\n",
    "                    break\n",
    "        cv2.imshow('frame', frame)\n",
    "        if key == 27:  # exit\n",
    "            break\n",
    "    stream.stop()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Model Specific data\n",
      "====> Height, Width, Channels : 512 512 3\n",
      "\u001b[32mweights ./models/ssd_mobilenet_face_epoch_05_loss0.0920.h5 loaded\u001b[0m\n",
      "[INFO] starting threaded video stream...\n",
      "[INFO] elasped time: 55.03\n",
      "[INFO] approx. FPS: 1.18\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stream' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5ffac8b9cc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stream' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model, model_layer, img_input, predictor_sizes = mn_model(image_size=(img_height, img_width, img_channels), \n",
    "                                                                      n_classes = n_classes,\n",
    "                                                                      min_scale = None, \n",
    "                                                                      max_scale = None, \n",
    "                                                                      scales = scales, \n",
    "                                                                      aspect_ratios_global = None, \n",
    "                                                                      aspect_ratios_per_layer = aspect_ratios, \n",
    "                                                                      two_boxes_for_ar1= two_boxes_for_ar1, \n",
    "                                                                      limit_boxes=limit_boxes, \n",
    "                                                                      variances= variances, \n",
    "                                                                      coords=coords, \n",
    "                                                                      normalize_coords=normalize_coords)\n",
    "    \n",
    "    model_path = './models/'\n",
    "    model_name = 'ssd_mobilenet_face_epoch_05_loss0.0920.h5'\n",
    "\n",
    "    model.load_weights(model_path + model_name,  by_name= True)\n",
    "\n",
    "    print (colored('weights %s loaded' % (model_path + model_name), 'green'))\n",
    "\n",
    "    fps = FPS().start()\n",
    "    cv2_demo(model)\n",
    "    # stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "    # cleanup\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
